---
title: "Biostat 203B Homework 2"
subtitle: Due Feb 10 @ 11:59PM
author: Saanchi Shah and UID: 204591578
format:
  html:
    theme: cosmo
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
---

Display machine information for reproducibility:
```{r}
#| eval: true
sessionInfo()

```

Load necessary libraries (you can add more as needed).
```{r setup, include = FALSE, echo = TRUE} 

#rm(list=ls())
library(data.table)
library(lubridate)
#install.packages("R.utils")
library(R.utils)
library(tidyverse)

#install.packages("scales")
library(scales) #To customize my graphs
```

MIMIC data location
```{r}
mimic_path <- "~/mimic"


```

In this exercise, we use tidyverse (ggplot2, dplyr, etc) to explore the [MIMIC-IV](https://mimic.mit.edu/docs/iv/) data introduced in [homework 1](https://ucla-biostat-203b.github.io/2023winter/hw/hw1/hw1.html) and to build a cohort of ICU stays.

Display the contents of MIMIC data folder. 


```{r}
system(str_c("ls -l ", mimic_path, "/"), intern = TRUE) #even without the forward slash, this code ran. 
system(str_c("ls -l ", mimic_path, "/core"), intern = TRUE)
system(str_c("ls -l ", mimic_path, "/hosp"), intern = TRUE)
system(str_c("ls -l ", mimic_path, "/icu"), intern = TRUE)

#question: why are we not running this in terminal as ls -l since it's the same output or a bash script?
```

## Q1. `read.csv` (base R) vs `read_csv` (tidyverse) vs `fread` (data.table)

There are quite a few utilities in R for reading plain text data files. Let us test the speed of reading a moderate sized compressed csv file, `admissions.csv.gz`, by three programs: `read.csv` in base R, `read_csv` in tidyverse, and `fread` in the popular data.table package. 

Which function is fastest? Is there difference in the (default) parsed data types? (Hint: R function `system.time` measures run times.)

For later questions, we stick to the `read_csv` in tidyverse.

```{r}
# Read the data in using read.csv

input_dir <- file.path("/Users/saanchishah/mimic/icu")
system.time(read.csv(file = file.path(input_dir, "admissions.csv.gz")))

#Read the data in using read_csv
system.time(read_csv(file = file.path(input_dir, "admissions.csv.gz"))) 
# Q: do we specify column types? should I use show_col_types = FALSE?
#Q: other than difference in the time are we supposed to mention any other difference?

#Use fread to read in the data
system.time(fread(file = file.path(input_dir, "admissions.csv.gz")))


```

Answer: fread is the fastest for parsing data. In fact, fread literally stands for fast and friendly file finagler. read.csv is the slowest option for reading the data in. 



## Q2. ICU stays

`icustays.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/icu/icustays/>) contains data about Intensive Care Units (ICU) stays. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/icu/icustays.csv"), 
    " | head"
    ), 
  intern = TRUE
)


#error writing to output: broken pipe.
```

1. Import `icustatys.csv.gz` as a tibble `icustays_tble`. 

```{r}

icustays_tble <- read_csv(file = file.path(input_dir, "icustays.csv")) %>% print(width = Inf)

icustays_tble <- as_tibble(icustays_tble) #confirms it's a tibble


```



2. How many unique `subject_id`? Can a `subject_id` have multiple ICU stays? 

```{r}
icustays_tble %>% distinct(subject_id)

#icustays_tble %>% count(subject_id) %>% filter(n==1) %>% count()
#How many had one icu stay only? - just for myself

```
There are 53150 unique subject ids. Yes, a subjct can have multiple ICU stays. In fact, there are 171080 individuals with just one stay and the rest had multiple icu stays.

3. Summarize the number of ICU stays per `subject_id` by graphs. 

I am going to try to be creative here. It does not make sense to have multiple subject_ids on the X-axis so I would cluster number of people by number of stays instead. 

```{r}

icustays_tble %>% group_by(subject_id) %>% summarise(stays = n()) %>% ggplot() + geom_freqpoly(mapping = aes(x = stays)) + xlab("Number of ICU stays") + ylab("Number of patients") + scale_x_continuous(breaks=seq(1,37,by=2)) + ggtitle("Distribution of number of ICU stays")


#grouped_icu <- icustays_tble %>% group_by(subject_id) %>% summarise(stays = n())
#table(grouped_icu$stays) - I did this to understand the range of icu stays
```


4. For each `subject_id`, let's only keep the first ICU stay in the tibble `icustays_tble`. (Hint: `slice_min` and `slice_max` may take long. Think alternative ways to achieve the same function.)

```{r}
new_icu <- icustays_tble %>% group_by(subject_id) %>% arrange(intime) %>% slice_head(n = 1)

#new_icu1 <- icustays_tble %>% group_by(subject_id) %>% filter(intime == min(intime))
#intime
```



## Q3. `admission` data

Information of the patients admitted into hospital is available in `admissions.csv.gz`. See <https://mimic.mit.edu/docs/iv/modules/hosp/admissions/> for details of each field in this file. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/core/admissions.csv.gz"), 
    " | head"
    ), 
  intern = TRUE
)
```

1. Import `admissions.csv.gz` as a tibble `admissions_tble`.

```{r}
input_admissions <- file.path("/Users/saanchishah/mimic/core") #There are multiple ways to input a filepath - this is an easier and efficient way to do so.

admissions_tble <- read_csv(file = file.path(input_admissions, "admissions.csv.gz")) %>% print(width = Inf)


```


2. Let's only keep the admissions that have a match in `icustays_tble` according to `subject_id` and `hadmi_id`.

This would require a type of join to ensure that observations with the same subject_id and hadmi_id are preserved/filtered by. I understand this question to mean that if subject id and hadmi id are present in icustays_tble then we can keep those observations in admissions. Let's attempt to do that using a semi join.

```{r}


new_admissions <- semi_join(admissions_tble, icustays_tble, by = c("subject_id", "hadm_id"))

#this makes sense because admissions_tble had 523740 distinct ids and after the semi join I expected there to 
#be fewer observations and I see 69211 observations now.



```


3. Summarize the following variables by graphics. 

    - admission year  
    - admission month  
    - admission month day  
    - admission week day  
    - admission hour (anything unusual?)  
    - admission minute (anything unusual?)  
    - length of hospital stay (anything unusual?)    
  
To create these graphs, we need to first manipulate some variables to extract specific variables from original variables  
Step 1: Data manipulation    
```{r}
#invertigating the variable admittime
typeof(admissions_tble$admittime)
class(admissions_tble$admittime)

new_admissions$time %>% mutate(year = year(new_admissions$admittime),
                               #month = month(new_admissions$admittime), #gives month as a numeric
                               month = months(new_admissions$admittime), #gives month as a character var
                               week_day = wday(new_admissions$admittime),
                               hour = hour(new_admissions$admittime),
                               minute = minute(new_admissions$admittime),
                               month_day)

```

    
    
## Q4. `patients` data

Patient information is available in `patients.csv.gz`. See <https://mimic.mit.edu/docs/iv/modules/hosp/patients/> for details of each field in this file. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/core/patients.csv.gz"), 
    " | head"
    ), 
  intern = TRUE
)
```

1. Import `patients.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/hosp/patients/>) as a tibble `patients_tble` and only keep the patients who have a match in `icustays_tble` (according to `subject_id`).


```{r}
patients_tble <- read_csv(file = file.path(input_admissions, "patients.csv.gz")) %>% print(width = Inf) %>% semi_join(patients_tble, icustays_tble, by = c("subject_id"))



```


2. Summarize variables `gender` and `anchor_age`, and explain any patterns you see.

```{r}
summary(patients_tble$anchor_age) 



```
This is me being lazy. But it is interesting that there are patients with age 0. Again since dates were deliberately fudged to protect their identity, it is not surprising. 

```{r}
class(patients_tble$gender)
table(patients_tble$gender) #me being lazy, 
```

It appears that the distribution of males and females is similar even while there is a higher number of females comapred to males in this dataset.



```


## Q5. Lab results

`labevents.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/hosp/labevents/>) contains all laboratory measurements for patients. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/hosp/labevents.csv.gz"), 
    " | head"
    ), 
  intern = TRUE
)
```
`d_labitems.csv.gz` is the dictionary of lab measurements. 
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/hosp/d_labitems.csv.gz"), 
    " | head"
    ), 
  intern = TRUE
)
```

1. Find how many rows are in `labevents.csv.gz`.

2. We are interested in the lab measurements of creatinine (50912), potassium (50971), sodium (50983), chloride (50902), bicarbonate (50882), hematocrit (51221), white blood cell count (51301), and glucose (50931). Retrieve a subset of `labevents.csv.gz` only containing these items for the patients in `icustays_tble` as a tibble `labevents_tble`. 

    Hint: `labevents.csv.gz` is a data file too big to be read in by the `read_csv` function in its default setting. Utilize the `col_select` option in the `read_csv` function to reduce the memory burden. It took my computer 5-10 minutes to ingest this file. If your computer really has trouble importing `labevents.csv.gz`, you can import from the reduced data file `labevents_filtered_itemid.csv.gz`.

3. Further restrict `labevents_tble` to the first lab measurement during the ICU stay. 

4. Summarize the lab measurements by appropriate numerics and graphics. 

## Q6. Vitals from charted events

`chartevents.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/icu/chartevents/>) contains all the charted data available for a patient. During their ICU stay, the primary repository of a patient’s information is their electronic chart. The `itemid` variable indicates a single measurement type in the database. The `value` variable is the value measured for `itemid`. The first 10 lines of `chartevents.csv.gz` are
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/icu/chartevents.csv.gz"), 
    " | head"), 
  intern = TRUE
)
```
`d_items.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/icu/d_items/>) is the dictionary for the `itemid` in `chartevents.csv.gz`. 
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/icu/d_items.csv.gz"), 
    " | head"), 
  intern = TRUE
)
```

1. We are interested in the vitals for ICU patients: heart rate (220045), mean non-invasive blood pressure (220181), systolic non-invasive blood pressure (220179), body temperature in Fahrenheit (223761), and respiratory rate (220210). Retrieve a subset of `chartevents.csv.gz` only containing these items for the patients in `icustays_tble` as a tibble `chartevents_tble`.

    Hint: `chartevents.csv.gz` is a data file too big to be read in by the `read_csv` function in its default setting. Utilize the `col_select` option in the `read_csv` function to reduce the memory burden. It took my computer >15 minutes to ingest this file. If your computer really has trouble importing `chartevents.csv.gz`, you can import from the reduced data file `chartevents_filtered_itemid.csv.gz`.

2. Further restrict `chartevents_tble` to the first vital measurement during the ICU stay. 

3. Summarize these vital measurements by appropriate numerics and graphics. 

## Q7. Putting things together

Let us create a tibble `mimic_icu_cohort` for all ICU stays, where rows are the first ICU stay of each unique adult (age at admission > 18) and columns contain at least following variables  

- all variables in `icustays.csv.gz`  
- all variables in `admission.csv.gz`  
- all variables in `patients.csv.gz`  
- first lab measurements during ICU stay  
- first vital measurements during ICU stay
- an indicator variable `thirty_day_mort` whether the patient died within 30 days of hospital admission (30 day mortality)

## Q8. Exploratory data analysis (EDA)

Summarize following information using appropriate numerics or graphs.

- `thirty_day_mort` vs demographic variables (ethnicity, language, insurance, marital_status, gender, age at hospital admission)

- `thirty_day_mort` vs first lab measurements

- `thirty_day_mort` vs first vital measurements

- `thirty_day_mort` vs first ICU unit
